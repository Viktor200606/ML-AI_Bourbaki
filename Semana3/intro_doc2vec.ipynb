{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2vec from scratch in PyTorch\n",
    "===============================\n",
    "\n",
    "Here we are implementing this useful algorithm with a library we know and trust. With luck this will be more accessible than reading the papers but more in-depth than typical \"install gensim and just do what I say\" tutorials, and still easy to understand for anyone whose maths skills have atrophied to nothing (like me). This is all based on the great work by [Nejc Ilenic](https://github.com/inejc/paragraph-vectors) and reading the referenced papers and gensim's source.\n",
    "\n",
    "`doc2vec` descends from `word2vec`, the basic form of which is that it is a model trained to predict the missing word in a context. Given sentences like \"the cat ___ on the mat\" it should predict \"sat\", and in doing so learn a useful representation of words. We can then extract the internal weights and re-use them as \"word embeddings\", vectors giving each word a position in N-dimensional space that is hopefully close to similar words and an appropriate distance from related words. \n",
    "\n",
    "`doc2vec` or \"Paragraph vectors\" extends the `word2vec` idea by simply adding a document id to each context. This helps the network learn associations between contexts and produces vectors that position each paragraph (document) in space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to load the data. We'll begin by overfitting on a tiny dataset just to check all the parts fit together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the week before their departure to Arrakis, when all the final scurrying about had reached a ...</td>\n",
       "      <td>[in, the, week, before, their, departure, to, arrakis, when, all, the, final, scurrying, about, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was a warm night at Castle Caladan, and the ancient pile of stone that had served the Atreide...</td>\n",
       "      <td>[it, was, a, warm, night, at, castle, caladan, and, the, ancient, pile, of, stone, that, had, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The old woman was let in by the side door down the vaulted passage by Paul's room and she was al...</td>\n",
       "      <td>[the, old, woman, was, let, in, by, the, side, door, down, the, vaulted, passage, by, paul, room...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>By the half-light of a suspensor lamp, dimmed and hanging near the floor, the awakened boy could...</td>\n",
       "      <td>[by, the, half, light, of, a, suspensor, lamp, dimmed, and, hanging, near, the, floor, the, awak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  In the week before their departure to Arrakis, when all the final scurrying about had reached a ...   \n",
       "1  It was a warm night at Castle Caladan, and the ancient pile of stone that had served the Atreide...   \n",
       "2  The old woman was let in by the side door down the vaulted passage by Paul's room and she was al...   \n",
       "3  By the half-light of a suspensor lamp, dimmed and hanging near the floor, the awakened boy could...   \n",
       "\n",
       "                                                                                                tokens  \n",
       "0  [in, the, week, before, their, departure, to, arrakis, when, all, the, final, scurrying, about, ...  \n",
       "1  [it, was, a, warm, night, at, castle, caladan, and, the, ancient, pile, of, stone, that, had, se...  \n",
       "2  [the, old, woman, was, let, in, by, the, side, door, down, the, vaulted, passage, by, paul, room...  \n",
       "3  [by, the, half, light, of, a, suspensor, lamp, dimmed, and, hanging, near, the, floor, the, awak...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "\n",
    "example_df = pd.read_csv(\"./Data/example.csv\")\n",
    "\n",
    "def tokenize_text(df):\n",
    "    df[\"tokens\"] = df.text.str.lower().str.strip().apply(lambda x: [token.text.strip() for token in nlp(x) if token.text.isalnum()])\n",
    "    return df\n",
    "\n",
    "example_df = tokenize_text(example_df)\n",
    "\n",
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to construct a vocabulary so we can reference every word by an ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset comprises 4 documents and 106 unique words (over the limit of 1 occurrences)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, all_tokens, min_count=2):\n",
    "        self.min_count = min_count\n",
    "        self.freqs = {t:n for t, n in Counter(all_tokens).items() if n >= min_count}\n",
    "        self.words = sorted(self.freqs.keys())\n",
    "        self.word2idx = {w: i for i, w in enumerate(self.words)}\n",
    "        \n",
    "vocab = Vocab([tok for tokens in example_df.tokens for tok in tokens], min_count=1)\n",
    "\n",
    "print(f\"Dataset comprises {len(example_df)} documents and {len(vocab.words)} unique words (over the limit of {vocab.min_count} occurrences)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words that appear extremely rarely can harm performance, so we add a simple mechanism to strip those out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>length</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>clean_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the week before their departure to Arrakis, when all the final scurrying about had reached a ...</td>\n",
       "      <td>[in, the, week, before, their, departure, to, arrakis, when, all, the, final, scurrying, about, ...</td>\n",
       "      <td>32</td>\n",
       "      <td>[in, the, week, before, their, departure, to, arrakis, when, all, the, final, scurrying, about, ...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was a warm night at Castle Caladan, and the ancient pile of stone that had served the Atreide...</td>\n",
       "      <td>[it, was, a, warm, night, at, castle, caladan, and, the, ancient, pile, of, stone, that, had, se...</td>\n",
       "      <td>39</td>\n",
       "      <td>[it, was, a, warm, night, at, castle, caladan, and, the, ancient, pile, of, stone, that, had, se...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The old woman was let in by the side door down the vaulted passage by Paul's room and she was al...</td>\n",
       "      <td>[the, old, woman, was, let, in, by, the, side, door, down, the, vaulted, passage, by, paul, room...</td>\n",
       "      <td>34</td>\n",
       "      <td>[the, old, woman, was, let, in, by, the, side, door, down, the, vaulted, passage, by, paul, room...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>By the half-light of a suspensor lamp, dimmed and hanging near the floor, the awakened boy could...</td>\n",
       "      <td>[by, the, half, light, of, a, suspensor, lamp, dimmed, and, hanging, near, the, floor, the, awak...</td>\n",
       "      <td>53</td>\n",
       "      <td>[by, the, half, light, of, a, suspensor, lamp, dimmed, and, hanging, near, the, floor, the, awak...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  In the week before their departure to Arrakis, when all the final scurrying about had reached a ...   \n",
       "1  It was a warm night at Castle Caladan, and the ancient pile of stone that had served the Atreide...   \n",
       "2  The old woman was let in by the side door down the vaulted passage by Paul's room and she was al...   \n",
       "3  By the half-light of a suspensor lamp, dimmed and hanging near the floor, the awakened boy could...   \n",
       "\n",
       "                                                                                                tokens  \\\n",
       "0  [in, the, week, before, their, departure, to, arrakis, when, all, the, final, scurrying, about, ...   \n",
       "1  [it, was, a, warm, night, at, castle, caladan, and, the, ancient, pile, of, stone, that, had, se...   \n",
       "2  [the, old, woman, was, let, in, by, the, side, door, down, the, vaulted, passage, by, paul, room...   \n",
       "3  [by, the, half, light, of, a, suspensor, lamp, dimmed, and, hanging, near, the, floor, the, awak...   \n",
       "\n",
       "   length  \\\n",
       "0      32   \n",
       "1      39   \n",
       "2      34   \n",
       "3      53   \n",
       "\n",
       "                                                                                          clean_tokens  \\\n",
       "0  [in, the, week, before, their, departure, to, arrakis, when, all, the, final, scurrying, about, ...   \n",
       "1  [it, was, a, warm, night, at, castle, caladan, and, the, ancient, pile, of, stone, that, had, se...   \n",
       "2  [the, old, woman, was, let, in, by, the, side, door, down, the, vaulted, passage, by, paul, room...   \n",
       "3  [by, the, half, light, of, a, suspensor, lamp, dimmed, and, hanging, near, the, floor, the, awak...   \n",
       "\n",
       "   clean_length  \n",
       "0            32  \n",
       "1            39  \n",
       "2            34  \n",
       "3            53  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_tokens(df, vocab):\n",
    "    df[\"length\"] = df.tokens.apply(len)\n",
    "    df[\"clean_tokens\"] = df.tokens.apply(lambda x: [t for t in x if t in vocab.freqs.keys()])\n",
    "    df[\"clean_length\"] = df.clean_tokens.apply(len)\n",
    "    return df\n",
    "\n",
    "example_df = clean_tokens(example_df, vocab)\n",
    "example_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difficulty with our \"the cat _ on the mat\" problem is that the missing word could be any one in the vocabulary V and so the network would have |V| outputs for each input e.g. a huge vector containing zero for every word in the vocabulary and some positive number for \"sat\" if the network was perfectly trained. For calculating loss we need to turn that into a probabilty distribution, i.e. _softmax_ it. Computing the softmax for such a large vector is expensive.\n",
    "\n",
    "So the trick (one of many possible) we will use is _Noise Contrastive Estimation (NCE)_. We change our \"the cat _ on the mat\" problem into a multiple choice problem, asking the network to choose between \"sat\" and some random wrong answers like \"hopscotch\" and \"luxuriated\". This is easier to compute the softmax for since it's now a binary classifier (right or wrong answer) and the output is simply of a vector of size 1 + k where k is the number of random incorrect options.\n",
    "\n",
    "Happily, this alternative problem still learns equally useful word representations. We just need to adjust the examples and the loss function. There is a simplified version of the NCE loss function called _Negative Sampling (NEG)_ that we can use here.\n",
    "\n",
    "[Notes on Noise Contrastive Estimation and Negative Sampling (C. Dyer)](https://arxiv.org/abs/1410.8251) explains the derivation of the NCE and NEG loss functions.\n",
    "\n",
    "When we implement the loss function, we assume that the first element in a samples/scores vector is the score for the positive sample and the rest are negative samples. This convention saves us from having to pass around an auxiliary vector indicating which sample was positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NegativeSampling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NegativeSampling, self).__init__()\n",
    "        self.log_sigmoid = nn.LogSigmoid()\n",
    "    def forward(self, scores):\n",
    "        batch_size = scores.shape[0]\n",
    "        n_negative_samples = scores.shape[1] - 1   # TODO average or sum the negative samples? Summing seems to be correct by the paper\n",
    "        positive = self.log_sigmoid(scores[:,0])\n",
    "        negatives = torch.sum(self.log_sigmoid(-scores[:,1:]), dim=1)\n",
    "        return -torch.sum(positive + negatives) / batch_size  # average for batch\n",
    "\n",
    "loss = NegativeSampling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's helpful to play with some values to reassure ourselves that this function does the right thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, -1, -1, -1]</td>\n",
       "      <td>tensor(1.2530)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.5, -1, -1, -1]</td>\n",
       "      <td>tensor(1.4139)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, -1, -1, -1]</td>\n",
       "      <td>tensor(1.6329)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>tensor(2.7726)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "      <td>tensor(3.3927)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0, 1, 1, 1]</td>\n",
       "      <td>tensor(4.6329)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.5, 1, 1, 1]</td>\n",
       "      <td>tensor(4.4139)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>tensor(4.2530)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              scores            loss\n",
       "0    [1, -1, -1, -1]  tensor(1.2530)\n",
       "1  [0.5, -1, -1, -1]  tensor(1.4139)\n",
       "2    [0, -1, -1, -1]  tensor(1.6329)\n",
       "3       [0, 0, 0, 0]  tensor(2.7726)\n",
       "4       [0, 0, 0, 1]  tensor(3.3927)\n",
       "5       [0, 1, 1, 1]  tensor(4.6329)\n",
       "6     [0.5, 1, 1, 1]  tensor(4.4139)\n",
       "7       [1, 1, 1, 1]  tensor(4.2530)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "data = [[[1, -1, -1, -1]],  # this dummy data uses -1 to 1, but the real model is unconstrained\n",
    "        [[0.5, -1, -1, -1]],\n",
    "        [[0, -1, -1, -1]],\n",
    "        [[0, 0, 0, 0]],\n",
    "        [[0, 0, 0, 1]],\n",
    "        [[0, 1, 1, 1]],\n",
    "        [[0.5, 1, 1, 1]],\n",
    "        [[1, 1, 1, 1]]]\n",
    "\n",
    "loss_df = pd.DataFrame(data, columns=[\"scores\"])\n",
    "loss_df[\"loss\"] = loss_df.scores.apply(lambda x: loss(torch.FloatTensor([x])))\n",
    "\n",
    "loss_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher scores for the positive sample (always the first element) reduce the loss but higher scores for the negative samples increase the loss. This looks like the right behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that in the bag, let's look at creating training data. The general idea is to create a set of examples where each example has:\n",
    "\n",
    "- doc id\n",
    "- sample ids - a collection of the target token and some noise tokens\n",
    "- context ids - tokens before and after the target token\n",
    "\n",
    "e.g. If our context size was 2, the first example from the above dataset would be:\n",
    "\n",
    "```\n",
    "{\"doc_id\": 0,\n",
    " \"sample_ids\": [word2idx[x] for x in [\"week\", \"random-word-from-vocab\", \"random-word-from-vocab\"...],\n",
    " \"context_ids\": [word2idx[x] for x in [\"in\", \"the\", \"before\", \"their\"]]}\n",
    " ```\n",
    " \n",
    " The random words are chosen according to a probability distribution:\n",
    " \n",
    " > a unigram distribution raised to the 3/4rd power, as proposed by T. Mikolov et al. in Distributed Representations of Words and Phrases and their Compositionality\n",
    "\n",
    "This has the effect of slightly increasing the relative probability of rare words (look at the graph of `y=x^0.75` below and see how the lower end is raised above `y=x`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-2f3eb3f9bde0466ca76343cf9bdced85.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-2f3eb3f9bde0466ca76343cf9bdced85.vega-embed details,\n",
       "  #altair-viz-2f3eb3f9bde0466ca76343cf9bdced85.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-2f3eb3f9bde0466ca76343cf9bdced85\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-2f3eb3f9bde0466ca76343cf9bdced85\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-2f3eb3f9bde0466ca76343cf9bdced85\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-afc3dc0951a9e12875119a5af86e52b5\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"x\": {\"field\": \"x\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y\", \"type\": \"quantitative\"}}, \"title\": \"x^0.75\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-afc3dc0951a9e12875119a5af86e52b5\": [{\"x\": 0.0, \"y\": 0.0}, {\"x\": 0.01, \"y\": 0.03162277660168379}, {\"x\": 0.02, \"y\": 0.053182958969449884}, {\"x\": 0.03, \"y\": 0.07208434242404263}, {\"x\": 0.04, \"y\": 0.08944271909999159}, {\"x\": 0.05, \"y\": 0.10573712634405642}, {\"x\": 0.06, \"y\": 0.12123093028059741}, {\"x\": 0.07, \"y\": 0.13608915892697748}, {\"x\": 0.08, \"y\": 0.15042412372345573}, {\"x\": 0.09, \"y\": 0.16431676725154984}, {\"x\": 0.1, \"y\": 0.1778279410038923}, {\"x\": 0.11, \"y\": 0.19100490227716513}, {\"x\": 0.12, \"y\": 0.2038853093816547}, {\"x\": 0.13, \"y\": 0.2164998073464082}, {\"x\": 0.14, \"y\": 0.22887377179317683}, {\"x\": 0.15, \"y\": 0.2410285256833955}, {\"x\": 0.16, \"y\": 0.25298221281347033}, {\"x\": 0.17, \"y\": 0.26475044029330763}, {\"x\": 0.18, \"y\": 0.2763467610958144}, {\"x\": 0.19, \"y\": 0.28778304315451386}, {\"x\": 0.2, \"y\": 0.29906975624424414}, {\"x\": 0.21, \"y\": 0.3102161981490854}, {\"x\": 0.22, \"y\": 0.32123067524150845}, {\"x\": 0.23, \"y\": 0.33212064831351956}, {\"x\": 0.24, \"y\": 0.34289285156385596}, {\"x\": 0.25, \"y\": 0.3535533905932738}, {\"x\": 0.26, \"y\": 0.3641078238014289}, {\"x\": 0.27, \"y\": 0.37456123052590357}, {\"x\": 0.28, \"y\": 0.38491826849295824}, {\"x\": 0.29, \"y\": 0.39518322257770583}, {\"x\": 0.3, \"y\": 0.4053600464421103}, {\"x\": 0.31, \"y\": 0.41545239829339137}, {\"x\": 0.32, \"y\": 0.42546367175559907}, {\"x\": 0.33, \"y\": 0.43539702265375557}, {\"x\": 0.34, \"y\": 0.4452553923589699}, {\"x\": 0.35000000000000003, \"y\": 0.45504152822405847}, {\"x\": 0.36, \"y\": 0.46475800154489}, {\"x\": 0.37, \"y\": 0.47440722340731084}, {\"x\": 0.38, \"y\": 0.4839914587188715}, {\"x\": 0.39, \"y\": 0.4935128386754873}, {\"x\": 0.4, \"y\": 0.5029733718731741}, {\"x\": 0.41000000000000003, \"y\": 0.5123749542422491}, {\"x\": 0.42, \"y\": 0.5217193779544038}, {\"x\": 0.43, \"y\": 0.5310083394307343}, {\"x\": 0.44, \"y\": 0.5402434465602292}, {\"x\": 0.45, \"y\": 0.549426225222706}, {\"x\": 0.46, \"y\": 0.5585581251971565}, {\"x\": 0.47000000000000003, \"y\": 0.5676405255254853}, {\"x\": 0.48, \"y\": 0.576674739392341}, {\"x\": 0.49, \"y\": 0.5856620185738529}, {\"x\": 0.5, \"y\": 0.5946035575013605}, {\"x\": 0.51, \"y\": 0.6035004969804791}, {\"x\": 0.52, \"y\": 0.6123539276009055}, {\"x\": 0.53, \"y\": 0.6211648928681236}, {\"x\": 0.54, \"y\": 0.629934392084505}, {\"x\": 0.55, \"y\": 0.6386633830041155}, {\"x\": 0.56, \"y\": 0.6473527842827909}, {\"x\": 0.5700000000000001, \"y\": 0.6560034777426358}, {\"x\": 0.58, \"y\": 0.6646163104680073}, {\"x\": 0.59, \"y\": 0.6731920967482075}, {\"x\": 0.6, \"y\": 0.6817316198804996}, {\"x\": 0.61, \"y\": 0.6902356338456498}, {\"x\": 0.62, \"y\": 0.6987048648669424}, {\"x\": 0.63, \"y\": 0.7071400128625219}, {\"x\": 0.64, \"y\": 0.7155417527999327}, {\"x\": 0.65, \"y\": 0.7239107359608682}, {\"x\": 0.66, \"y\": 0.7322475911233668}, {\"x\": 0.67, \"y\": 0.7405529256680135}, {\"x\": 0.68, \"y\": 0.7488273266140879}, {\"x\": 0.6900000000000001, \"y\": 0.7570713615910638}, {\"x\": 0.7000000000000001, \"y\": 0.7652855797503655}, {\"x\": 0.71, \"y\": 0.7734705126218591}, {\"x\": 0.72, \"y\": 0.7816266749191567}, {\"x\": 0.73, \"y\": 0.7897545652974598}, {\"x\": 0.74, \"y\": 0.7978546670673515}, {\"x\": 0.75, \"y\": 0.8059274488676564}, {\"x\": 0.76, \"y\": 0.8139733653002305}, {\"x\": 0.77, \"y\": 0.8219928575293057}, {\"x\": 0.78, \"y\": 0.829986353847804}, {\"x\": 0.79, \"y\": 0.837954270212839}, {\"x\": 0.8, \"y\": 0.8458970107524514}, {\"x\": 0.81, \"y\": 0.8538149682454624}, {\"x\": 0.8200000000000001, \"y\": 0.8617085245761865}, {\"x\": 0.8300000000000001, \"y\": 0.869578051165608}, {\"x\": 0.84, \"y\": 0.8774239093805121}, {\"x\": 0.85, \"y\": 0.8852464509219427}, {\"x\": 0.86, \"y\": 0.8930460181942644}, {\"x\": 0.87, \"y\": 0.9008229446560111}, {\"x\": 0.88, \"y\": 0.9085775551536168}, {\"x\": 0.89, \"y\": 0.9163101662390513}, {\"x\": 0.9, \"y\": 0.9240210864723069}, {\"x\": 0.91, \"y\": 0.9317106167096201}, {\"x\": 0.92, \"y\": 0.9393790503782488}, {\"x\": 0.93, \"y\": 0.9470266737385726}, {\"x\": 0.9400000000000001, \"y\": 0.9546537661342305}, {\"x\": 0.9500000000000001, \"y\": 0.9622606002309622}, {\"x\": 0.96, \"y\": 0.9698474422447793}, {\"x\": 0.97, \"y\": 0.9774145521600454}, {\"x\": 0.98, \"y\": 0.9849621839380145}, {\"x\": 0.99, \"y\": 0.992490585716335}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame(zip(np.arange(0,1,0.01), np.power(np.arange(0,1,0.01), 0.75)), columns=[\"x\", \"y\"])\n",
    "alt.Chart(data, title=\"x^0.75\").mark_line().encode(x=\"x\", y=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NoiseDistribution:\n",
    "    def __init__(self, vocab):\n",
    "        self.probs = np.array([vocab.freqs[w] for w in vocab.words])\n",
    "        self.probs = np.power(self.probs, 0.75)\n",
    "        self.probs /= np.sum(self.probs)\n",
    "    def sample(self, n):\n",
    "        \"Returns the indices of n words randomly sampled from the vocabulary.\"\n",
    "        return np.random.choice(a=self.probs.shape[0], size=n, p=self.probs)\n",
    "        \n",
    "noise = NoiseDistribution(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this distribution, we advance through the documents creating examples. Note that we are always putting the positive sample first in the samples vector, following the convention the loss function expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def example_generator(df, context_size, noise, n_negative_samples, vocab):\n",
    "    for doc_id, doc in df.iterrows():\n",
    "        for i in range(context_size, len(doc.clean_tokens) - context_size):\n",
    "            positive_sample = vocab.word2idx[doc.clean_tokens[i]]\n",
    "            sample_ids = noise.sample(n_negative_samples).tolist()\n",
    "            # Fix a wee bug - ensure negative samples don't accidentally include the positive\n",
    "            sample_ids = [sample_id if sample_id != positive_sample else -1 for sample_id in sample_ids]\n",
    "            sample_ids.insert(0, positive_sample)                \n",
    "            context = doc.clean_tokens[i - context_size:i] + doc.clean_tokens[i + 1:i + context_size + 1]\n",
    "            context_ids = [vocab.word2idx[w] for w in context]\n",
    "            yield {\"doc_ids\": torch.tensor(doc_id),  # we use plural here because it will be batched\n",
    "                   \"sample_ids\": torch.tensor(sample_ids), \n",
    "                   \"context_ids\": torch.tensor(context_ids)}\n",
    "            \n",
    "examples = example_generator(example_df, context_size=5, noise=noise, n_negative_samples=5, vocab=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we package this up as a good old PyTorch dataset and dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NCEDataset(Dataset):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = list(examples)  # just naively evaluate the whole damn thing - suboptimal!\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    def __getitem__(self, index):\n",
    "        return self.examples[index]\n",
    "    \n",
    "dataset = NCEDataset(examples)\n",
    "dataloader = DataLoader(dataset, batch_size=2, drop_last=True, shuffle=True)  # TODO bigger batch size when not dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's going to also be useful to have a way to convert batches back to a readable form for debugging, so we add a helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc_id': tensor(1),\n",
       "  'context': 'was a warm night at ____ caladan and the ancient pile',\n",
       "  'context_ids': tensor([99,  0, 98, 65, 11, 20,  8, 91,  7, 72]),\n",
       "  'samples': ['castle', 'allowed', 'before', 'paul', 'one', 'was'],\n",
       "  'sample_ids': tensor([22,  5, 15, 70, 68, 99])},\n",
       " {'doc_id': tensor(3),\n",
       "  'context': 'the old woman was a ____ shadow hair like matted spiderwebs',\n",
       "  'context_ids': tensor([ 91,  67, 105,  99,   0,  79,  44,  59,  60,  84]),\n",
       "  'samples': ['witch', 'scurrying', 'dimmed', 'all', 'hair', 'down'],\n",
       "  'sample_ids': tensor([104,  76,  29,   4,  44,  31])}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def describe_batch(batch, vocab):\n",
    "    results = []\n",
    "    for doc_id, context_ids, sample_ids in zip(batch[\"doc_ids\"], batch[\"context_ids\"], batch[\"sample_ids\"]):\n",
    "        context = [vocab.words[i] for i in context_ids]\n",
    "        context.insert(len(context_ids) // 2, \"____\")\n",
    "        samples = [vocab.words[i] for i in sample_ids]\n",
    "        result = {\"doc_id\": doc_id,\n",
    "                  \"context\": \" \".join(context), \n",
    "                  \"context_ids\": context_ids, \n",
    "                  \"samples\": samples, \n",
    "                  \"sample_ids\": sample_ids}\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "describe_batch(next(iter(dataloader)), vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's jump into creating the model itself. There isn't much to it - we multiply the input paragraph and word matrices by the output layer. Combining the paragraph and word matrices is done by summing here, but it could also be done by concatenating the inputs. The original paper actually found concatenation works better, perhaps because summing loses word order information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DistributedMemory(nn.Module):\n",
    "    def __init__(self, vec_dim, n_docs, n_words):\n",
    "        super(DistributedMemory, self).__init__()\n",
    "        self.paragraph_matrix = nn.Parameter(torch.randn(n_docs, vec_dim))\n",
    "        self.word_matrix = nn.Parameter(torch.randn(n_words, vec_dim))\n",
    "        self.outputs = nn.Parameter(torch.zeros(vec_dim, n_words))\n",
    "    \n",
    "    def forward(self, doc_ids, context_ids, sample_ids):\n",
    "                                                                               # first add doc ids to context word ids to make the inputs\n",
    "        inputs = torch.add(self.paragraph_matrix[doc_ids,:],                   # (batch_size, vec_dim)\n",
    "                           torch.sum(self.word_matrix[context_ids,:], dim=1))  # (batch_size, 2x context, vec_dim) -> sum to (batch_size, vec_dim)\n",
    "                                                                               #\n",
    "                                                                               # select the subset of the output layer for the NCE test\n",
    "        outputs = self.outputs[:,sample_ids]                                   # (vec_dim, batch_size, n_negative_samples + 1)\n",
    "                                                                               #\n",
    "        return torch.bmm(inputs.unsqueeze(dim=1),                              # then multiply with some munging to make the tensor shapes line up \n",
    "                         outputs.permute(1, 0, 2)).squeeze()                   # -> (batch_size, n_negative_samples + 1)\n",
    "\n",
    "model = DistributedMemory(vec_dim=50,\n",
    "                          n_docs=len(example_df),\n",
    "                          n_words=len(vocab.words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take it for a spin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model.forward(**next(iter(dataloader)))\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh yeah, the output layer was initialized with zeros. Time to bash out a standard issue PyTorch training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "from torch.optim import Adam  # ilenic uses Adam, but gensim uses plain SGD\n",
    "import numpy as np\n",
    "\n",
    "def train(model, dataloader, epochs=40, lr=1e-3):\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    training_losses = []\n",
    "    try:\n",
    "        for epoch in trange(epochs, desc=\"Epochs\"):\n",
    "            epoch_losses = []\n",
    "            for batch in dataloader:\n",
    "                model.zero_grad()\n",
    "                logits = model.forward(**batch)\n",
    "                batch_loss = loss(logits)\n",
    "                epoch_losses.append(batch_loss.item())\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            training_losses.append(np.mean(epoch_losses))\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"Interrupted on epoch {epoch}!\")\n",
    "    finally:\n",
    "        return training_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll sanity check by overfitting the example data. Training loss should drop from untrained loss to something close to the minimum possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 40/40 [00:02<00:00, 16.89it/s]\n"
     ]
    }
   ],
   "source": [
    "training_losses = train(model, dataloader, epochs=40, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-436b4b11b6e84889a9998427fa55df23.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-436b4b11b6e84889a9998427fa55df23.vega-embed details,\n",
       "  #altair-viz-436b4b11b6e84889a9998427fa55df23.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-436b4b11b6e84889a9998427fa55df23\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-436b4b11b6e84889a9998427fa55df23\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-436b4b11b6e84889a9998427fa55df23\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-75c9d72626fc33179d4796de62032f9e\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"training_loss\", \"scale\": {\"type\": \"log\"}, \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-75c9d72626fc33179d4796de62032f9e\": [{\"epoch\": 0, \"training_loss\": 3.930350311731888}, {\"epoch\": 1, \"training_loss\": 2.571921469801563}, {\"epoch\": 2, \"training_loss\": 1.868319309363931}, {\"epoch\": 3, \"training_loss\": 1.4620603403802646}, {\"epoch\": 4, \"training_loss\": 1.1868285041744426}, {\"epoch\": 5, \"training_loss\": 0.9810846740916624}, {\"epoch\": 6, \"training_loss\": 0.8210837588471881}, {\"epoch\": 7, \"training_loss\": 0.706924435950942}, {\"epoch\": 8, \"training_loss\": 0.5985595912246381}, {\"epoch\": 9, \"training_loss\": 0.5282900836003028}, {\"epoch\": 10, \"training_loss\": 0.4609085904844737}, {\"epoch\": 11, \"training_loss\": 0.40624617153810244}, {\"epoch\": 12, \"training_loss\": 0.3604194756786702}, {\"epoch\": 13, \"training_loss\": 0.3237779350098917}, {\"epoch\": 14, \"training_loss\": 0.29219075759588664}, {\"epoch\": 15, \"training_loss\": 0.2614297936275854}, {\"epoch\": 16, \"training_loss\": 0.23566022540553141}, {\"epoch\": 17, \"training_loss\": 0.21458323754496494}, {\"epoch\": 18, \"training_loss\": 0.1979317544501717}, {\"epoch\": 19, \"training_loss\": 0.18039454608145405}, {\"epoch\": 20, \"training_loss\": 0.16626791182463452}, {\"epoch\": 21, \"training_loss\": 0.1534924990166042}, {\"epoch\": 22, \"training_loss\": 0.14145361449001198}, {\"epoch\": 23, \"training_loss\": 0.13017279888361188}, {\"epoch\": 24, \"training_loss\": 0.12116474948697172}, {\"epoch\": 25, \"training_loss\": 0.11260790068466785}, {\"epoch\": 26, \"training_loss\": 0.10309043886550402}, {\"epoch\": 27, \"training_loss\": 0.09570534966128358}, {\"epoch\": 28, \"training_loss\": 0.09032928590047157}, {\"epoch\": 29, \"training_loss\": 0.08443012994603585}, {\"epoch\": 30, \"training_loss\": 0.07948309953434993}, {\"epoch\": 31, \"training_loss\": 0.07449568110376091}, {\"epoch\": 32, \"training_loss\": 0.07127314490281929}, {\"epoch\": 33, \"training_loss\": 0.06674537545669887}, {\"epoch\": 34, \"training_loss\": 0.06132365248592223}, {\"epoch\": 35, \"training_loss\": 0.059541309915356715}, {\"epoch\": 36, \"training_loss\": 0.05466317868460033}, {\"epoch\": 37, \"training_loss\": 0.052083968042822205}, {\"epoch\": 38, \"training_loss\": 0.04777747889885963}, {\"epoch\": 39, \"training_loss\": 0.046722701734910575}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "df_loss = pd.DataFrame(enumerate(training_losses), columns=[\"epoch\", \"training_loss\"])\n",
    "alt.Chart(df_loss).mark_bar().encode(alt.X(\"epoch\"), alt.Y(\"training_loss\", scale=alt.Scale(type=\"log\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And because we're paranoid types, let's check a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.8357, -5.9906, -5.3293, -6.3565, -6.4887, -6.1140],\n",
       "        [ 3.6154, -4.6326, -6.3030, -7.4115, -6.3481, -6.7937]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model.forward(**next(iter(dataloader)))\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positive sample gets a positive score and the negatives get negative scores. Super."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should be able get the paragraph vectors for the documents and do things like check these for similarity to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>It was a warm night at Castle Caladan, and the ancient pile of stone that had served the Atreide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.156679</td>\n",
       "      <td>By the half-light of a suspensor lamp, dimmed and hanging near the floor, the awakened boy could...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.050358</td>\n",
       "      <td>In the week before their departure to Arrakis, when all the final scurrying about had reached a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.090432</td>\n",
       "      <td>The old woman was let in by the side door down the vaulted passage by Paul's room and she was al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  similarity  \\\n",
       "1       1    1.000000   \n",
       "3       3    0.156679   \n",
       "0       0    0.050358   \n",
       "2       2   -0.090432   \n",
       "\n",
       "                                                                                                  text  \n",
       "1  It was a warm night at Castle Caladan, and the ancient pile of stone that had served the Atreide...  \n",
       "3  By the half-light of a suspensor lamp, dimmed and hanging near the floor, the awakened boy could...  \n",
       "0  In the week before their departure to Arrakis, when all the final scurrying about had reached a ...  \n",
       "2  The old woman was let in by the side door down the vaulted passage by Paul's room and she was al...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def most_similar(paragraph_matrix, docs_df, index, n=None):\n",
    "    pm = normalize(paragraph_matrix, norm=\"l2\")  # in a smarter implementation we would cache this somewhere\n",
    "    sims = np.dot(pm, pm[index,:])\n",
    "    df = pd.DataFrame(enumerate(sims), columns=[\"doc_id\", \"similarity\"])\n",
    "    n = n if n is not None else len(sims)\n",
    "    return df.merge(docs_df[[\"text\"]].reset_index(drop=True), left_index=True, right_index=True).sort_values(by=\"similarity\", ascending=False)[:n]\n",
    "\n",
    "most_similar(model.paragraph_matrix.data, example_df, 1, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not particularly illuminating for our tiny set of dummy data though. We can also use PCA to reduce our n-dimensional paragraph vectors to 2 dimensions and see if they are clustered nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-component PCA, explains 48.31% of variance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-3b44f761f50747619e3db5233e3f8326.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-3b44f761f50747619e3db5233e3f8326.vega-embed details,\n",
       "  #altair-viz-3b44f761f50747619e3db5233e3f8326.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-3b44f761f50747619e3db5233e3f8326\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-3b44f761f50747619e3db5233e3f8326\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-3b44f761f50747619e3db5233e3f8326\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-579fa58252b9927650eeab73fef0460c\"}, \"mark\": {\"type\": \"point\"}, \"encoding\": {\"color\": {\"field\": \"group\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-579fa58252b9927650eeab73fef0460c\": [{\"x\": 6.63116662040862, \"y\": -3.267831634717744, \"group\": \"0\"}, {\"x\": -3.66627240097671, \"y\": -3.450159321846734, \"group\": \"1\"}, {\"x\": 1.56294510342061, \"y\": 6.475076610851, \"group\": \"2\"}, {\"x\": -4.527839322852525, \"y\": 0.242914345713474, \"group\": \"3\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca_2d(paragraph_matrix, groups):\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_dims = pca.fit_transform(paragraph_matrix)\n",
    "    print(f\"2-component PCA, explains {sum(pca.explained_variance_):.2f}% of variance\")\n",
    "    df = pd.DataFrame(reduced_dims, columns=[\"x\", \"y\"])\n",
    "    df[\"group\"] = groups\n",
    "    return df\n",
    "\n",
    "example_2d = pca_2d(model.paragraph_matrix.data, [\"0\",\"1\",\"2\",\"3\"])\n",
    "alt.Chart(example_2d).mark_point().encode(x=\"x\", y=\"y\", color=\"group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much to see on such a tiny dataset without any labelled groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this on some bigger data\n",
    "--------------------------------\n",
    "\n",
    "We'll use the BBC's dataset. The dataset was created by Derek Greene at UCD and all articles are copyright Auntie. I've munged it into a file per topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claxton hunting first major medal  British hurdler Sarah Claxton is confident she can win her fi...</td>\n",
       "      <td>[claxton, hunting, first, major, medal, british, hurdler, sarah, claxton, is, confident, she, ca...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O'Sullivan could run in Worlds  Sonia O'Sullivan has indicated that she would like to participat...</td>\n",
       "      <td>[could, run, in, worlds, sonia, has, indicated, that, she, would, like, to, participate, in, nex...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greene sets sights on world title  Maurice Greene aims to wipe out the pain of losing his Olympi...</td>\n",
       "      <td>[greene, sets, sights, on, world, title, maurice, greene, aims, to, wipe, out, the, pain, of, lo...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IAAF launches fight against drugs  The IAAF - athletics' world governing body - has met anti-dop...</td>\n",
       "      <td>[iaaf, launches, fight, against, drugs, the, iaaf, athletics, world, governing, body, has, met, ...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  Claxton hunting first major medal  British hurdler Sarah Claxton is confident she can win her fi...   \n",
       "1  O'Sullivan could run in Worlds  Sonia O'Sullivan has indicated that she would like to participat...   \n",
       "2  Greene sets sights on world title  Maurice Greene aims to wipe out the pain of losing his Olympi...   \n",
       "3  IAAF launches fight against drugs  The IAAF - athletics' world governing body - has met anti-dop...   \n",
       "\n",
       "                                                                                                tokens  \\\n",
       "0  [claxton, hunting, first, major, medal, british, hurdler, sarah, claxton, is, confident, she, ca...   \n",
       "1  [could, run, in, worlds, sonia, has, indicated, that, she, would, like, to, participate, in, nex...   \n",
       "2  [greene, sets, sights, on, world, title, maurice, greene, aims, to, wipe, out, the, pain, of, lo...   \n",
       "3  [iaaf, launches, fight, against, drugs, the, iaaf, athletics, world, governing, body, has, met, ...   \n",
       "\n",
       "   group  \n",
       "0  sport  \n",
       "1  sport  \n",
       "2  sport  \n",
       "3  sport  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for document_set in (\"sport\",\n",
    "                     \"business\",\n",
    "                     \"politics\", \n",
    "                     \"tech\", \n",
    "                     \"entertainment\"):\n",
    "    df_ = pd.read_csv(f\"./Data/bbc/{document_set}.csv.bz2\", encoding=\"latin1\")\n",
    "    df_ = tokenize_text(df_)\n",
    "    df_[\"group\"] = document_set\n",
    "    dfs.append(df_)\n",
    "\n",
    "bbc_df = pd.concat(dfs)\n",
    "bbc_df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset comprises 2225 documents and 19065 unique words\n"
     ]
    }
   ],
   "source": [
    "bbc_vocab = Vocab([tok for tokens in bbc_df.tokens for tok in tokens])\n",
    "\n",
    "bbc_df = clean_tokens(bbc_df, bbc_vocab)\n",
    "\n",
    "print(f\"Dataset comprises {len(bbc_df)} documents and {len(bbc_vocab.words)} unique words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_noise = NoiseDistribution(bbc_vocab)\n",
    "bbc_examples = list(example_generator(bbc_df, context_size=5, noise=bbc_noise, n_negative_samples=5, vocab=bbc_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_dataset = NCEDataset(bbc_examples)\n",
    "bbc_dataloader = DataLoader(bbc_dataset, batch_size=1024, drop_last=True, shuffle=True)  # TODO could tolerate a larger batch size\n",
    "\n",
    "bbc_model = DistributedMemory(vec_dim=50,\n",
    "                              n_docs=len(bbc_df),\n",
    "                              n_words=len(bbc_vocab.words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 80/80 [18:39<00:00, 13.99s/it]  \n"
     ]
    }
   ],
   "source": [
    "bbc_training_losses = train(bbc_model, bbc_dataloader, epochs=80, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-76d95d7ad0d541c5a3309531cadc979f.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-76d95d7ad0d541c5a3309531cadc979f.vega-embed details,\n",
       "  #altair-viz-76d95d7ad0d541c5a3309531cadc979f.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-76d95d7ad0d541c5a3309531cadc979f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-76d95d7ad0d541c5a3309531cadc979f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-76d95d7ad0d541c5a3309531cadc979f\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-d8ec975c1e8a04d6f1de88960850b8f1\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-d8ec975c1e8a04d6f1de88960850b8f1\": [{\"epoch\": 0, \"training_loss\": 2.6411681823044204}, {\"epoch\": 1, \"training_loss\": 2.1714515106257966}, {\"epoch\": 2, \"training_loss\": 1.9868299703740009}, {\"epoch\": 3, \"training_loss\": 1.8709007937914088}, {\"epoch\": 4, \"training_loss\": 1.787698035352579}, {\"epoch\": 5, \"training_loss\": 1.7225748201457798}, {\"epoch\": 6, \"training_loss\": 1.6684131459621874}, {\"epoch\": 7, \"training_loss\": 1.622296985266522}, {\"epoch\": 8, \"training_loss\": 1.5812197187106602}, {\"epoch\": 9, \"training_loss\": 1.544660657274516}, {\"epoch\": 10, \"training_loss\": 1.5110717137753225}, {\"epoch\": 11, \"training_loss\": 1.479967958578105}, {\"epoch\": 12, \"training_loss\": 1.451549120339803}, {\"epoch\": 13, \"training_loss\": 1.4247716162399973}, {\"epoch\": 14, \"training_loss\": 1.3998030554272105}, {\"epoch\": 15, \"training_loss\": 1.3764493268713467}, {\"epoch\": 16, \"training_loss\": 1.3542082509391065}, {\"epoch\": 17, \"training_loss\": 1.3329162927478477}, {\"epoch\": 18, \"training_loss\": 1.312822699990521}, {\"epoch\": 19, \"training_loss\": 1.2936244759311155}, {\"epoch\": 20, \"training_loss\": 1.2754822706170472}, {\"epoch\": 21, \"training_loss\": 1.2576792775549308}, {\"epoch\": 22, \"training_loss\": 1.2407336887295726}, {\"epoch\": 23, \"training_loss\": 1.2245335777107598}, {\"epoch\": 24, \"training_loss\": 1.2087298915640592}, {\"epoch\": 25, \"training_loss\": 1.1935399111092238}, {\"epoch\": 26, \"training_loss\": 1.1787116598550498}, {\"epoch\": 27, \"training_loss\": 1.1645911257556887}, {\"epoch\": 28, \"training_loss\": 1.1505920138607546}, {\"epoch\": 29, \"training_loss\": 1.1373685395747202}, {\"epoch\": 30, \"training_loss\": 1.1242331227948588}, {\"epoch\": 31, \"training_loss\": 1.1115419133277449}, {\"epoch\": 32, \"training_loss\": 1.099260291006074}, {\"epoch\": 33, \"training_loss\": 1.0871627585172061}, {\"epoch\": 34, \"training_loss\": 1.0755335693028074}, {\"epoch\": 35, \"training_loss\": 1.0641305969459542}, {\"epoch\": 36, \"training_loss\": 1.0530053873363854}, {\"epoch\": 37, \"training_loss\": 1.0421402897343741}, {\"epoch\": 38, \"training_loss\": 1.0313927676186667}, {\"epoch\": 39, \"training_loss\": 1.0210985456299841}, {\"epoch\": 40, \"training_loss\": 1.0109400230808827}, {\"epoch\": 41, \"training_loss\": 1.0010005850206238}, {\"epoch\": 42, \"training_loss\": 0.991377632907839}, {\"epoch\": 43, \"training_loss\": 0.9817383343321514}, {\"epoch\": 44, \"training_loss\": 0.9725311556761673}, {\"epoch\": 45, \"training_loss\": 0.9633613108257502}, {\"epoch\": 46, \"training_loss\": 0.9543575789437401}, {\"epoch\": 47, \"training_loss\": 0.9457256229728387}, {\"epoch\": 48, \"training_loss\": 0.9371311756280752}, {\"epoch\": 49, \"training_loss\": 0.9286692688985735}, {\"epoch\": 50, \"training_loss\": 0.9204809588770713}, {\"epoch\": 51, \"training_loss\": 0.9123242322179875}, {\"epoch\": 52, \"training_loss\": 0.9044773661469112}, {\"epoch\": 53, \"training_loss\": 0.896772926779598}, {\"epoch\": 54, \"training_loss\": 0.8892302468012343}, {\"epoch\": 55, \"training_loss\": 0.8818104315188623}, {\"epoch\": 56, \"training_loss\": 0.874343523094731}, {\"epoch\": 57, \"training_loss\": 0.8673326060286822}, {\"epoch\": 58, \"training_loss\": 0.8602219846645005}, {\"epoch\": 59, \"training_loss\": 0.8532495074177499}, {\"epoch\": 60, \"training_loss\": 0.8465331919287925}, {\"epoch\": 61, \"training_loss\": 0.8397525192490287}, {\"epoch\": 62, \"training_loss\": 0.8333093430061198}, {\"epoch\": 63, \"training_loss\": 0.8268420780562881}, {\"epoch\": 64, \"training_loss\": 0.8204670578019495}, {\"epoch\": 65, \"training_loss\": 0.8141765260962636}, {\"epoch\": 66, \"training_loss\": 0.8081514142435182}, {\"epoch\": 67, \"training_loss\": 0.8021311314762674}, {\"epoch\": 68, \"training_loss\": 0.7961031617804734}, {\"epoch\": 69, \"training_loss\": 0.7904189729660971}, {\"epoch\": 70, \"training_loss\": 0.7846857186582484}, {\"epoch\": 71, \"training_loss\": 0.7791464927770364}, {\"epoch\": 72, \"training_loss\": 0.7735529658812151}, {\"epoch\": 73, \"training_loss\": 0.7681089749850942}, {\"epoch\": 74, \"training_loss\": 0.7628299460813366}, {\"epoch\": 75, \"training_loss\": 0.7575225613401191}, {\"epoch\": 76, \"training_loss\": 0.7523032841700182}, {\"epoch\": 77, \"training_loss\": 0.7473075880158332}, {\"epoch\": 78, \"training_loss\": 0.7423416269624203}, {\"epoch\": 79, \"training_loss\": 0.7374578048810178}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(pd.DataFrame(enumerate(bbc_training_losses), columns=[\"epoch\", \"training_loss\"])).mark_bar().encode(x=\"epoch\", y=\"training_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the reduced dimensionality paragraph vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-component PCA, explains 2.64% of variance\n"
     ]
    }
   ],
   "source": [
    "bbc_2d = pca_2d(bbc_model.paragraph_matrix.data, bbc_df.group.to_numpy())\n",
    "chart = alt.Chart(bbc_2d).mark_point().encode(x=\"x\", y=\"y\", color=\"group\")\n",
    "# Uncomment to print chart inline, but beware it will inflate the notebook size\n",
    "# chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2-component PCA, explains 2.65% of variance`\n",
    "\n",
    "![](./img/bbc_pca_all_topics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results aren't great, but we can see the beginnings of separation. If we look at just two topics it becomes more obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = alt.Chart(bbc_2d[bbc_2d[\"group\"].isin([\"sport\", \"business\"])]).mark_point().encode(x=\"x\", y=\"y\", color=\"group\")\n",
    "# Uncomment to print chart inline, but beware it will inflate the notebook size\n",
    "# chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/bbc_pca_business_sport.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise we can see sorting by similarity produces reasonable, but not ideal, results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Claxton hunting first major medal  British hurdler Sarah Claxton is confident she can win her fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>477</td>\n",
       "      <td>0.495819</td>\n",
       "      <td>Clijsters hope on Aussie Open  Kim Clijsters has denied reports that she has pulled out of Janua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>486</td>\n",
       "      <td>0.469268</td>\n",
       "      <td>Officials respond in court row  Australian tennis' top official has defended the Australian Open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>762</td>\n",
       "      <td>0.460628</td>\n",
       "      <td>BT offers equal access to rivals  BT has moved to pre-empt a possible break-up of its business b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.454369</td>\n",
       "      <td>Bekele sets sights on world mark  Olympic 10,000m champion Kenenisa Bekele is determined to add ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>1059</td>\n",
       "      <td>0.442762</td>\n",
       "      <td>'Hitler' row over Welsh arts cash  An artist critical of Welsh arts funding being brought under ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>288</td>\n",
       "      <td>0.442663</td>\n",
       "      <td>Fuming Robinson blasts officials  England coach Andy Robinson insisted he was 'livid' after his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>223</td>\n",
       "      <td>0.435558</td>\n",
       "      <td>Bristol City 2-1 Milton Keynes  Leroy Lita took his goal tally to 13 for the season as his doubl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>405</td>\n",
       "      <td>0.434914</td>\n",
       "      <td>Fuming Robinson blasts officials  England coach Andy Robinson said he was 'livid' after his side...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.432069</td>\n",
       "      <td>Ronaldo considering new contract  Manchester United winger Cristiano Ronaldo said he is close to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_id  similarity  \\\n",
       "0          0    1.000000   \n",
       "477      477    0.495819   \n",
       "486      486    0.469268   \n",
       "762      762    0.460628   \n",
       "31        31    0.454369   \n",
       "1059    1059    0.442762   \n",
       "288      288    0.442663   \n",
       "223      223    0.435558   \n",
       "405      405    0.434914   \n",
       "97        97    0.432069   \n",
       "\n",
       "                                                                                                     text  \n",
       "0     Claxton hunting first major medal  British hurdler Sarah Claxton is confident she can win her fi...  \n",
       "477   Clijsters hope on Aussie Open  Kim Clijsters has denied reports that she has pulled out of Janua...  \n",
       "486   Officials respond in court row  Australian tennis' top official has defended the Australian Open...  \n",
       "762   BT offers equal access to rivals  BT has moved to pre-empt a possible break-up of its business b...  \n",
       "31    Bekele sets sights on world mark  Olympic 10,000m champion Kenenisa Bekele is determined to add ...  \n",
       "1059  'Hitler' row over Welsh arts cash  An artist critical of Welsh arts funding being brought under ...  \n",
       "288   Fuming Robinson blasts officials  England coach Andy Robinson insisted he was 'livid' after his ...  \n",
       "223   Bristol City 2-1 Milton Keynes  Leroy Lita took his goal tally to 13 for the season as his doubl...  \n",
       "405   Fuming Robinson blasts officials  England coach Andy Robinson said he was 'livid' after his side...  \n",
       "97    Ronaldo considering new contract  Manchester United winger Cristiano Ronaldo said he is close to...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(bbc_model.paragraph_matrix.data, bbc_df, 0, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps\n",
    "----------\n",
    "\n",
    "That's all for now! I honestly hope that was fun and educational (it was for me, anyway).\n",
    "\n",
    "But data science projects are notorious for never being finished. To carry this on, we could:\n",
    "\n",
    "- look for better hyperparameters, since the training loss remains quite high\n",
    "- benchmark against `gensim` and Ilenic's PyTorch implementation; it should be very similar to the latter\n",
    "- implement the inference step for new documents, which freezes the word and output matrices and adds a new column to the paragraph matrix\n",
    "- use inferred paragraph vectors as the input for a topic classifier; looking at the business/sport plot above it could be quite successful\n",
    "- try visualization with a better dimensionality reduction algorithm than PCA (I've used [LargeVis](https://arxiv.org/abs/1602.00370) in the past)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
